{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM191jx9pf4ggnWZtlXtIzO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daini10421/MiniProjectWebCrawling/blob/main/WebCrawling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-bAIjbAf6gv",
        "outputId": "36ca206e-3ea8-438e-f44e-5b100b1489f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting emailcrawl1\n",
            "  Downloading emailcrawl1-0.0.3-py3-none-any.whl (2.3 kB)\n",
            "Installing collected packages: emailcrawl1\n",
            "Successfully installed emailcrawl1-0.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install emailcrawl1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests_html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kl-Zx8legHVU",
        "outputId": "f05cb0b1-b5e9-4a85-91aa-b133f2d66787"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting requests_html\n",
            "  Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests_html) (2.27.1)\n",
            "Collecting pyquery (from requests_html)\n",
            "  Downloading pyquery-2.0.0-py3-none-any.whl (22 kB)\n",
            "Collecting fake-useragent (from requests_html)\n",
            "  Downloading fake_useragent-1.1.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parse (from requests_html)\n",
            "  Downloading parse-1.19.1-py2.py3-none-any.whl (18 kB)\n",
            "Collecting bs4 (from requests_html)\n",
            "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting w3lib (from requests_html)\n",
            "  Downloading w3lib-2.1.1-py3-none-any.whl (21 kB)\n",
            "Collecting pyppeteer>=0.0.14 (from requests_html)\n",
            "  Downloading pyppeteer-1.0.2-py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.4/83.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (2023.5.7)\n",
            "Collecting importlib-metadata>=1.4 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading importlib_metadata-6.7.0-py3-none-any.whl (22 kB)\n",
            "Collecting pyee<9.0.0,>=8.1.0 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading pyee-8.2.2-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (4.65.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests_html) (1.26.16)\n",
            "Collecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests_html)\n",
            "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests_html) (4.11.2)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests_html) (4.9.2)\n",
            "Collecting cssselect>=1.2.0 (from pyquery->requests_html)\n",
            "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests_html) (3.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests_html) (3.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests_html) (2.4.1)\n",
            "Building wheels for collected packages: bs4\n",
            "  Building wheel for bs4 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=0a2aaafa6c4b1ecf2ad55d8f94de54ca5485d8774e664ca374f1d03310741ffc\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/42/45/b773edc52acb16cd2db4cf1a0b47117e2f69bb4eb300ed0e70\n",
            "Successfully built bs4\n",
            "Installing collected packages: pyee, parse, fake-useragent, websockets, w3lib, importlib-metadata, cssselect, pyquery, pyppeteer, bs4, requests_html\n",
            "Successfully installed bs4-0.0.1 cssselect-1.2.0 fake-useragent-1.1.3 importlib-metadata-6.7.0 parse-1.19.1 pyee-8.2.2 pyppeteer-1.0.2 pyquery-2.0.0 requests_html-0.10.0 w3lib-2.1.1 websockets-10.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from emailcrawl1 import emailcrawl1"
      ],
      "metadata": {
        "id": "hmOd2zOCgL1Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emailcrawl1.email(\"https://thapar.edu/sitemap.xml\",100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DT8ord7gQCz",
        "outputId": "8ab4d907-1f6e-4345-df98-bab21ea18167"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|▏         | 59/4342 [00:41<50:48,  1.41it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install requests-html\n",
        "!pip install re\n",
        "!pip install request\n",
        "!pip install bs4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5GeVkiRgeZ_",
        "outputId": "7cbe439c-5c32-4102-8bb5-b8e9a182a73e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: requests-html in /usr/local/lib/python3.10/dist-packages (0.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.27.1)\n",
            "Requirement already satisfied: pyquery in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.0.0)\n",
            "Requirement already satisfied: fake-useragent in /usr/local/lib/python3.10/dist-packages (from requests-html) (1.1.3)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.10/dist-packages (from requests-html) (1.19.1)\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (from requests-html) (0.0.1)\n",
            "Requirement already satisfied: w3lib in /usr/local/lib/python3.10/dist-packages (from requests-html) (2.1.1)\n",
            "Requirement already satisfied: pyppeteer>=0.0.14 in /usr/local/lib/python3.10/dist-packages (from requests-html) (1.0.2)\n",
            "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
            "Requirement already satisfied: certifi>=2021 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2023.5.7)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (6.7.0)\n",
            "Requirement already satisfied: pyee<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.2.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.65.0)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.8 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (1.26.16)\n",
            "Requirement already satisfied: websockets<11.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (10.4)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4->requests-html) (4.11.2)\n",
            "Requirement already satisfied: lxml>=2.1 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (4.9.2)\n",
            "Requirement already satisfied: cssselect>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyquery->requests-html) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->requests-html) (3.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.15.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4->requests-html) (2.4.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement re (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for re\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement request (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for request\u001b[0m\u001b[31m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.10/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from bs4) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->bs4) (2.4.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import deque\n",
        "from urllib.parse import urlsplit\n",
        "import pandas as pd\n",
        "from requests_html import HTMLSession\n",
        "import threading\n",
        "import time\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "b_xIuHu-g9IL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#user_url = \"https://www.thapar.edu/sitemap.xml\"\n",
        "#url = [\"https://www.thapar.edu\"]\n",
        "EMAIL_REGEX = r\"\"\"(?:[a-z0-9!#$%&'*+/=?^_`{|}~-]+(?:\\.[a-z0-9!#$%&'*+/=?^_`{|}~-]+)*|\"(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21\\x23-\\x5b\\x5d-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])*\")@(?:(?:[a-z0-9](?:[a-z0-9-]*[a-z0-9])?\\.)+[a-z0-9](?:[a-z0-9-]*[a-z0-9])?|\\[(?:(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9]))\\.){3}(?:(2(5[0-5]|[0-4][0-9])|1[0-9][0-9]|[1-9]?[0-9])|[a-z0-9-]*[a-z0-9]:(?:[\\x01-\\x08\\x0b\\x0c\\x0e-\\x1f\\x21-\\x5a\\x53-\\x7f]|\\\\[\\x01-\\x09\\x0b\\x0c\\x0e-\\x7f])+)\\])\"\"\""
      ],
      "metadata": {
        "id": "S3hK8BSJg_1f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_urls_of_xml(xml_url):\n",
        "    r = requests.get(xml_url)\n",
        "    xml = r.text\n",
        "    soup = BeautifulSoup(xml)\n",
        "\n",
        "    links_arr = []\n",
        "    for link in soup.findAll('loc'):\n",
        "        linkstr = link.getText('', True)\n",
        "        links_arr.append(linkstr)\n",
        "\n",
        "    return links_arr\n",
        "\n",
        "\n",
        "\n",
        "links_data_arr = get_urls_of_xml(\"https://thapar.edu/sitemap.xml\")\n",
        "#print(links_data_arr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En8ic278hBUG",
        "outputId": "d790a1fe-ac5e-4441-91bf-65716dac6a00"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-12-26T10:05:09.357183Z",
          "iopub.status.busy": "2022-12-26T10:05:09.356725Z",
          "iopub.status.idle": "2022-12-26T10:05:09.364213Z",
          "shell.execute_reply": "2022-12-26T10:05:09.362512Z",
          "shell.execute_reply.started": "2022-12-26T10:05:09.357144Z"
        },
        "trusted": true,
        "id": "2p6hNPpAjaHM"
      },
      "outputs": [],
      "source": [
        "session = HTMLSession()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "email=set()\n",
        "for i in tqdm(links_data_arr):\n",
        "        #requests.get(f'{i}', verify=False)\n",
        "        r = session.get(i)\n",
        "        for re_match in re.finditer(EMAIL_REGEX, r.html.raw_html.decode()):\n",
        "            email.add(((re_match.group())).replace(\"-\",\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V02-n_JxhJCj",
        "outputId": "85639a11-c56b-493c-b51f-45977bc74ac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 79/4342 [01:04<2:32:23,  2.14s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(email)\n",
        "df.to_csv('Emails.csv', index=False)"
      ],
      "metadata": {
        "id": "kRRNr4oujpJM"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}